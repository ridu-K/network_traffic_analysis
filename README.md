# ğŸš¨ Network Traffic Anomaly Detection Using Machine Learning & Deep Learning

This project focuses on **detecting anomalies in network traffic data** using multiple **unsupervised and hybrid machine learning techniques**, including **Autoencoders**, **Isolation Forest + Random Forest**, and **K-Means clustering**. The dataset consists of packet-level network traffic captured in CSV format.

---

## ğŸ“Œ Project Overview

* ğŸ“‚ **Input Data**: Network traffic logs (`late.csv`)
* ğŸ” **Goal**: Identify anomalous network packets
* ğŸ§  **Models Used**:

  * Deep Learning Autoencoder
  * Isolation Forest + Random Forest (Hybrid)
  * K-Means Clustering
* ğŸ“Š **Approach**: Unsupervised & semi-supervised anomaly detection
* ğŸ–¥ï¸ **Platform**: Python (Google Colab / Local)

---

## ğŸ“ Dataset Description

The dataset contains **117,084 network packets** with the following attributes:

| Column      | Description                                  |
| ----------- | -------------------------------------------- |
| No.         | Packet number                                |
| Time        | Timestamp of packet                          |
| Source      | Source IP address                            |
| Destination | Destination IP address                       |
| Protocol    | Network protocol (UDP, TCP, HTTP, TLS, etc.) |
| Length      | Packet length                                |
| Info        | Packet metadata                              |

---

## ğŸ› ï¸ Tech Stack

* **Python**
* **Pandas & NumPy**
* **Scikit-learn**
* **TensorFlow / Keras**
* **Matplotlib**

---

## ğŸ” Exploratory Data Analysis (EDA)

* Packet count and structure analysis
* Source & destination IP frequency analysis
* Protocol-wise traffic distribution
* Visualization of:

  * Top source IPs
  * Top destination IPs
  * Protocol usage
  * Packet length distribution

---

## ğŸ§  Model 1: Autoencoder-Based Anomaly Detection

### ğŸ”§ Feature Engineering

* Selected features:

  * `Protocol` (One-Hot Encoded)
  * `Length`
* Feature scaling using **MinMaxScaler**

### ğŸ—ï¸ Autoencoder Architecture

* Dense layers with ReLU activation
* Bottleneck encoding dimension: **10**
* Dropout layers for regularization
* Reconstruction loss: **Mean Squared Error (MSE)**

### âš™ï¸ Training Details

* Optimizer: Adam
* Epochs: 20
* Batch Size: 32

### ğŸš¨ Anomaly Detection

* Reconstruction error calculated per packet
* Threshold set at **99.9th percentile**
* **88 anomalies detected**

---

## ğŸŒ² Model 2: Isolation Forest + Random Forest (Hybrid)

### ğŸ”§ Preprocessing

* Protocol encoded using **LabelEncoder**
* Features used:

  * `Protocol`
  * `Length`

### ğŸ§  Workflow

1. **Isolation Forest**

   * Identifies potential anomalies
   * Contamination rate: 0.45%
2. **Random Forest Classifier**

   * Learns anomaly patterns
   * Refines predictions

### ğŸ“Œ Output

* **503 anomalies detected**
* Visualized using scatter plots (`Length vs Index`)

---

## ğŸ”µ Model 3: K-Means Clustering for Anomaly Detection

### âš™ï¸ Steps

* Numeric feature selection
* Standardization using **StandardScaler**
* K-Means clustering (`k = 2`)
* Distance from cluster centroids used as anomaly score

### ğŸš¨ Detection Strategy

* Top **0.1%** highest anomaly scores flagged
* **118 anomalies detected**

### ğŸ“Š Visualization

* Histogram of anomaly scores
* Clear separation between normal and anomalous packets

---

## ğŸ“ˆ Visualization Outputs

* Bar charts for protocol and IP frequencies
* Scatter plots highlighting anomalies
* Histogram of anomaly scores
* Comparative anomaly detection across models

---

## ğŸ“Š Results Summary

| Model                 | Anomalies Detected |
| --------------------- | ------------------ |
| Autoencoder           | 88                 |
| Isolation Forest + RF | 503                |
| K-Means               | 118                |

Each method captures **different anomaly characteristics**, improving overall reliability when combined.

---

## ğŸ§ª Key Observations

* High packet lengths often correlate with anomalies
* TLS/SSL traffic frequently appears in anomalous clusters
* Autoencoders are effective for subtle deviations
* Tree-based models catch structural irregularities

---

## ğŸš€ How to Run

1. Install dependencies:

   ```bash
   pip install numpy pandas scikit-learn tensorflow matplotlib
   ```
2. Place `late.csv` in the project directory
3. Run the notebook / script sequentially
4. Visualize and inspect detected anomalies

---

## ğŸ“Œ Applications

* Intrusion Detection Systems (IDS)
* Network traffic monitoring
* Cybersecurity threat analysis
* Abnormal traffic pattern detection
* Research in network anomaly detection

---

## ğŸ”® Future Enhancements

* Include time-based features
* Apply LSTM / Temporal Autoencoders
* Combine models using ensemble voting
* Real-time packet stream analysis
* Deploy using Flask / FastAPI
